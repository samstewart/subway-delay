{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from scipy.stats import binom,beta\n",
    "def posterior(A, B, initial, O):\n",
    "    # now compute P(X(t) | o_1, ..., o_t)\n",
    "    forward = np.empty((T, 2))\n",
    "    normalization =  np.empty(T)\n",
    "    forward[0] = initial\n",
    "\n",
    "    for i in range(1, T):\n",
    "        forward[i] = forward[i - 1] @ A @ np.diag(B[:, int(O[i]) - 2])\n",
    "        normalization[i] = forward[i].sum()\n",
    "        forward[i] /= normalization[i]\n",
    "\n",
    "    # now compute backward P(o_{t + 1}, .. o_T | X_t)\n",
    "    backward = np.empty((T, 2))\n",
    "    # in any state of X(T) we have prob 1 of seeing o_T\n",
    "    # by def\n",
    "    backward[T - 1] = np.ones(2)\n",
    "\n",
    "    for i in reversed(range((T - 1))):\n",
    "        # transpose or left mult because\n",
    "        # we are going backward in time\n",
    "        backward[i] = A @ np.diag(B[:, int(O[i + 1]) - 2]) @ backward[i + 1]\n",
    "        backward[i] /= normalization[i + 1]\n",
    "    # these will not be normalized as prob dist\n",
    "    # since we are using normalization to make\n",
    "    # entire conditional (prod) work\n",
    "    return forward * backward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 0., 1., 1., 1., 0., 1., 1., 0., 0.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling two coins with replacement.\n",
    "# Emissions are two states: heads or tails\n",
    "# for some reason, the processing of selecting\n",
    "# the coin is biased, so we might select p0\n",
    "# three times in a row more often on average than\n",
    "# p1. So the flips are no longer independent.\n",
    "# We can also view this as a single Bernoulli\n",
    "# dist with a p that depends in a markovian way\n",
    "# on time. This is closer to our model of the trains."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# Model is HMM with two states:\n",
    "A = np.array([[.1, .9],\n",
    "              [.3, .7]])\n",
    "# chance of success for each coin\n",
    "p = np.array([.1, .75])\n",
    "# emission probabilities\n",
    "B = np.array([1 - p, p]).transpose()\n",
    "# one sample up to time T\n",
    "T = 1000\n",
    "initial = np.array([.2, .8])\n",
    "# sample hidden state\n",
    "X = np.empty(T)\n",
    "X[0] = np.random.binomial(1, initial[1])\n",
    "\n",
    "for i in range(1, T):\n",
    "    X[i] = np.random.binomial(1, A[int(X[i - 1]), 1])\n",
    "\n",
    "# now generate emissions\n",
    "O = np.empty(T)\n",
    "for i in range(T):\n",
    "    O[i] = np.random.binomial(1, B[int(X[i]), 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.23746761, 0.76253239],\n       [0.034726  , 0.965274  ],\n       [0.53298487, 0.46701513],\n       [0.37586272, 0.62413728],\n       [0.43704601, 0.56295399],\n       [0.37632166, 0.62367834],\n       [0.53135079, 0.46864921],\n       [0.04008531, 0.95991469],\n       [0.06337539, 0.93662461],\n       [0.06364725, 0.93635275],\n       [0.03462594, 0.96537406],\n       [0.64617162, 0.35382838],\n       [0.02315005, 0.97684995],\n       [0.49886404, 0.50113596],\n       [0.49151119, 0.50848881],\n       [0.04197743, 0.95802257],\n       [0.06334907, 0.93665093],\n       [0.06233302, 0.93766698],\n       [0.06238133, 0.93761867],\n       [0.06237889, 0.93762111],\n       [0.06238213, 0.93761787],\n       [0.06231626, 0.93768374],\n       [0.06370156, 0.93629844],\n       [0.03456305, 0.96543695],\n       [0.64746603, 0.35253397],\n       [0.01916998, 0.98083002],\n       [0.64747521, 0.35252479],\n       [0.03453458, 0.96546542],\n       [0.06477208, 0.93522792],\n       [0.04025581, 0.95974419],\n       [0.52686224, 0.47313776],\n       [0.39016465, 0.60983535],\n       [0.3902776 , 0.6097224 ],\n       [0.52657303, 0.47342697],\n       [0.04117264, 0.95882736],\n       [0.03516238, 0.96483762],\n       [0.64726896, 0.35273104],\n       [0.01918197, 0.98081803],\n       [0.64722088, 0.35277912],\n       [0.03531153, 0.96468847],\n       [0.03556427, 0.96443573],\n       [0.64214551, 0.35785449],\n       [0.03478685, 0.96521315],\n       [0.06479459, 0.93520541],\n       [0.03954015, 0.96045985],\n       [0.54193805, 0.45806195],\n       [0.3437934 , 0.6562066 ],\n       [0.54690054, 0.45309946],\n       [0.02187095, 0.97812905],\n       [0.64634454, 0.35365546],\n       [0.03536055, 0.96463945],\n       [0.03531528, 0.96468472],\n       [0.6472536 , 0.3527464 ],\n       [0.01907594, 0.98092406],\n       [0.6512283 , 0.3487717 ],\n       [0.02298744, 0.97701256],\n       [0.49891217, 0.50108783],\n       [0.49149557, 0.50850443],\n       [0.04197807, 0.95802193],\n       [0.06335206, 0.93664794],\n       [0.06227033, 0.93772967],\n       [0.06370087, 0.93629913],\n       [0.03462451, 0.96537549],\n       [0.64617209, 0.35382791],\n       [0.02315003, 0.97684997],\n       [0.49886404, 0.50113596],\n       [0.49151119, 0.50848881],\n       [0.04197743, 0.95802257],\n       [0.06334907, 0.93665093],\n       [0.06233288, 0.93766712],\n       [0.06238429, 0.93761571],\n       [0.06231673, 0.93768327],\n       [0.06368952, 0.93631048],\n       [0.03481636, 0.96518364],\n       [0.64213803, 0.35786197],\n       [0.03555813, 0.96444187],\n       [0.03555813, 0.96444187],\n       [0.64213803, 0.35786197],\n       [0.03481636, 0.96518364],\n       [0.06368937, 0.93631063],\n       [0.06231982, 0.93768018],\n       [0.06231936, 0.93768064],\n       [0.06369849, 0.93630151],\n       [0.03462458, 0.96537542],\n       [0.64617207, 0.35382793],\n       [0.02315003, 0.97684997],\n       [0.49886424, 0.50113576],\n       [0.49151059, 0.50848941],\n       [0.04197946, 0.95802054],\n       [0.06328587, 0.93671413],\n       [0.0636425 , 0.9363575 ],\n       [0.03481762, 0.96518238],\n       [0.64213762, 0.35786238],\n       [0.03555815, 0.96444185],\n       [0.03555814, 0.96444186],\n       [0.64213781, 0.35786219],\n       [0.03481702, 0.96518298],\n       [0.06366461, 0.93633539],\n       [0.06283012, 0.93716988],\n       [0.05157506, 0.94842494]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior(A, B, initial, O)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.32363317, 0.67636683],\n       [0.32524681, 0.67475319]])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 40\n",
    "sampled_p = np.empty((K, 2))\n",
    "sampled_p[0] = np.array([.2, .6])\n",
    "\n",
    "# initial conditions don't matter?\n",
    "# might cause problems with converging\n",
    "# to local minima\n",
    "# dirichlet multinomial vs dirichlet?\n",
    "sampled_X = np.empty((K, T))\n",
    "sampled_X[0] = np.ones(T)\n",
    "\n",
    "sampled_A = np.empty((K, 2, 2))\n",
    "sampled_A[0] = np.array([[.2, .8],\n",
    "                         [.4, .6]])\n",
    "sampled_B = np.empty((K, 2, 2))\n",
    "sampled_B[0] =  np.array([1 - sampled_p[0], sampled_p[0]]).transpose()\n",
    "\n",
    "A_prior = np.ones((2,2))\n",
    "\n",
    "# p_0: (success, failures)\n",
    "# p_1: (success, failures)\n",
    "p_prior = np.ones((2, 2))\n",
    "for i in range(1, K):\n",
    "    # sample from posterior\n",
    "    X_posterior = posterior(sampled_A[i - 1], sampled_B[i - 1], initial, O)[:, 1]\n",
    "    sampled_X[i] = np.random.binomial(1,X_posterior)\n",
    "    # use conjugate priors (beta for p, Dirichlet for rows of A)\n",
    "\n",
    "    # total number of heads / tails in coin p0\n",
    "    # total number of heads / tails in coin p1\n",
    "    # update counts. each row is different hypothess\n",
    "    # that we are flipping coin p0 or p1\n",
    "    # this is really estimating emission matrix\n",
    "    # H = 0, T = 1\n",
    "    p_prior +=  np.array([\n",
    "        [(1 - O) @ (1 - sampled_X[i]), (1 - O) @ sampled_X[i]],\n",
    "        [O @ (1 - sampled_X[i]), O @ sampled_X[i]]])\n",
    "\n",
    "    sampled_p[i] = np.random.beta(p_prior[:, 0], p_prior[:, 1])\n",
    "\n",
    "    # does that give rows of B a dirichlet distr?\n",
    "    # feels that it should\n",
    "    sampled_B[i] = np.array([1 - sampled_p[i], sampled_p[i]]).transpose()\n",
    "    # now estimate transition counts\n",
    "    for m in range(1, T):\n",
    "        i0 = sampled_X[i, m - 1]\n",
    "        i1 = sampled_X[i, m]\n",
    "        A_prior[int(i0), int(i1)] += 1\n",
    "    # if we iterate, do we loop through rows?\n",
    "    sampled_A[i] = np.vstack([\n",
    "        np.random.dirichlet(A_prior[i, :], 1)\n",
    "            for i in range(A_prior.shape[0])])\n",
    "\n",
    "sampled_A[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}